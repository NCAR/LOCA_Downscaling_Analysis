{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write cache for future hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last executed: 2020-05-23 08:01:52.473235 by jvano on casper02\n"
     ]
    }
   ],
   "source": [
    "from loca import print_date\n",
    "print_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "# from mpl_toolkits.basemap import Basemap  #2020: commented out because appears to be a missing file\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from loca.data_catalog import load_monthly_cmip_hydro_datasets, resample_monthly_data\n",
    "from loca.utils import calc_change\n",
    "\n",
    "\n",
    "#cache is written in script \"write_cache.ipynb\"  TODO\n",
    "read_cache = False\n",
    "# cache_dir = os.environ['TMPDIR']\n",
    "# cache_dir = '/glade/u/home/jvano/scratch/'  #old\n",
    "\n",
    "cache_dir = '/glade/scratch/jvano'  #new in 2020\n",
    "\n",
    "\n",
    "# TODO still need to clean this up, possibly add others - or migrate this script to another place.  \n",
    "# LIke that have ability to do individual models\n",
    "\n",
    "# CACHED:\n",
    "# models = ['ACCESS1-0', 'CanESM2']\n",
    "# models = ['MIROC5']\n",
    "# models = ['MRI-CGCM3']\n",
    "# models = ['bcc-csm1-1']\n",
    "# models = ['bcc-csm1-1-m']\n",
    "# models = ['CCSM4']\n",
    "# models = ['CESM1-BGC']\n",
    "# models = ['CMCC-CM']\n",
    "# models = ['GISS-E2-R']\n",
    "# models = ['HadGEM2-CC']\n",
    "# models = ['HadGEM2-ES', 'inmcm4']\n",
    "# models = ['IPSL-CM5A-MR']\n",
    "# models = ['MIROC-ESM', 'MIROC-ESM-CHEM']\n",
    "# models = ['MPI-ESM-LR']\n",
    "# models = ['MPI-ESM-MR']\n",
    "# models = ['GFDL-ESM2G'] \n",
    "# models = ['NorESM1-M']\n",
    "# models = ['MIROC5', 'MRI-CGCM3', 'bcc-csm1-1', 'bcc-csm1-1-m', 'CCSM4']\n",
    "# models = ['CESM1-BGC', 'CESM1-CAM5', 'CMCC-CM', 'GISS-E2-R', 'HadGEM2-CC','HadGEM2-ES', 'inmcm4']\n",
    "# models = ['IPSL-CM5A-MR']\n",
    "# models = ['MIROC-ESM', 'MIROC-ESM-CHEM']\n",
    "# models = ['MPI-ESM-LR', 'MPI-ESM-MR', 'NorESM1-M']\n",
    "# models = ['GFDL-ESM2G']\n",
    "# models = ['CNRM-CM5']\n",
    "# models = ['CSIRO-Mk3-6-0']\n",
    "# models = ['GFDL-ESM2M'] \n",
    "# models = ['GFDL-CM3'] \n",
    "# models = ['HadGEM2-AO']\n",
    "\n",
    "\n",
    "# list of 25, without issues but CCSM4 and GISS-E2-R are not used in analysis:\n",
    "# models = ['ACCESS1-0', 'CanESM2', 'MIROC5', 'MRI-CGCM3', 'bcc-csm1-1', 'bcc-csm1-1-m', 'CCSM4',\n",
    "#           'CESM1-BGC', 'CMCC-CM', 'GISS-E2-R', 'HadGEM2-CC', 'HadGEM2-ES', 'inmcm4', 'IPSL-CM5A-MR',\n",
    "#           'MIROC-ESM', 'MIROC-ESM-CHEM', 'MPI-ESM-LR', 'MPI-ESM-MR', 'NorESM1-M', 'GFDL-ESM2G', \n",
    "#           'CNRM-CM5', 'CSIRO-Mk3-6-0', 'GFDL-ESM2M','GFDL-CM3', 'HadGEM2-AO']\n",
    "\n",
    "# list of 23:\n",
    "models = ['ACCESS1-0', 'CanESM2', 'MIROC5', 'MRI-CGCM3', 'bcc-csm1-1', 'bcc-csm1-1-m',\n",
    "          'CESM1-BGC', 'CMCC-CM', 'HadGEM2-CC', 'HadGEM2-ES', 'inmcm4', 'IPSL-CM5A-MR',\n",
    "          'MIROC-ESM', 'MIROC-ESM-CHEM', 'MPI-ESM-LR', 'MPI-ESM-MR', 'NorESM1-M', 'GFDL-ESM2G', \n",
    "          'CNRM-CM5', 'CSIRO-Mk3-6-0', 'GFDL-ESM2M','GFDL-CM3', 'HadGEM2-AO']\n",
    "\n",
    "# models = ['ACCESS1-0']\n",
    "# models = ['MIROC5', 'MRI-CGCM3', 'bcc-csm1-1', 'bcc-csm1-1-m', 'CCSM4']\n",
    "# models = ['CESM1-BGC', 'CMCC-CM', 'GISS-E2-R', 'HadGEM2-CC', 'inmcm4', 'IPSL-CM5A-MR']\n",
    "# models = ['MIROC-ESM', 'MIROC-ESM-CHEM', 'MPI-ESM-LR', 'MPI-ESM-MR', 'NorESM1-M', 'GFDL-ESM2G'] \n",
    "models = ['CNRM-CM5', 'CSIRO-Mk3-6-0', 'GFDL-ESM2M','GFDL-CM3', 'HadGEM2-AO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.12.205.11:45598\n",
       "  <li><b>Dashboard: </b><a href='proxy/8787/status' target='_blank'>proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>60.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.12.205.11:45598' processes=2 cores=4>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(scheduler_file=os.path.join(os.environ['HOME'], 'scheduler_file.json'))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBSERVATIONS\n",
    "\n",
    "#TODO CHANGE SO WRITE ALL, NOT JUST FUT HYDRO\n",
    "read_cache = False\n",
    "\n",
    "from loca.data_catalog import load_monthly_historical_hydro_datasets\n",
    "\n",
    "hist_cmip_data = {}\n",
    "if read_cache:\n",
    "    print(\"reading values from cache\")\n",
    "    for key in ['loca', 'bcsd']:\n",
    "        hist_cmip_data[key] = xr.open_mfdataset(\n",
    "            os.path.join(cache_dir, f'monthly_cmip_hydro_hist.{key}_*.nc'),\n",
    "            concat_dim='gcm', chunks={'time': 72})\n",
    "    print(\"finished reading from cache\")\n",
    "    #TODO once get obs load separate won't have to do work around below\n",
    "    single = ['ACCESS1-0']\n",
    "    obs_data = load_monthly_historical_hydro_datasets(models=single, autoclose=True, parallel=True)\n",
    "    #obs_data = load_monthly_historical_hydro_datasets(single, autoclose=True, parallel=True) #appears to work without \"models\"\n",
    "    print(\"finished reading obs\")\n",
    "    # Merge two\n",
    "    x = obs_data\n",
    "    y = hist_cmip_data\n",
    "    hydro_data = {**x, **y}\n",
    "\n",
    "# if write_cache:\n",
    "#     hydro_data['livneh'].sel().load().to_netcdf(os.path.join(cache_dir, f'monthly_hydro_obs.livneh.nc'))\n",
    "#     hydro_data['maurer'].sel().load().to_netcdf(os.path.join(cache_dir, f'monthly_hydro_obs.maurer.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO why below not working, ask Joe  (or don't really need to change this as long as can cache it)\n",
    "# from loca.data_catalog import load_monthly_obs_hydro_datasets\n",
    "# obs_data = load_monthly_obs_hydro_datasets(autoclose=True, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_monthly_cmip_hydro_datasets\n",
      "load_monthly_loca_hydrology\n",
      "load_daily_loca_hydrology\n",
      "load_monthly_bcsd_hydrology\n",
      "load_bcsd_dataset\n",
      "load_monthly_cmip_hydro_datasets\n",
      "load_monthly_loca_hydrology\n",
      "load_daily_loca_hydrology\n",
      "load_monthly_bcsd_hydrology\n",
      "load_bcsd_dataset\n",
      "load_monthly_cmip_hydro_datasets\n",
      "load_monthly_loca_hydrology\n",
      "load_daily_loca_hydrology\n",
      "load_monthly_bcsd_hydrology\n",
      "load_bcsd_dataset\n"
     ]
    }
   ],
   "source": [
    "write_cache = True  \n",
    "models\n",
    "\n",
    "if write_cache:\n",
    "    xr.set_options(file_cache_maxsize=12000)\n",
    "    hist_data = load_monthly_cmip_hydro_datasets('historical', models=models, autoclose=False, parallel=True)\n",
    "    rcp4_data = load_monthly_cmip_hydro_datasets('rcp45', models=models, autoclose=False, parallel=True)\n",
    "    rcp8_data = load_monthly_cmip_hydro_datasets('rcp85', models=models, autoclose=False, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb6541677c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgcm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TMPDIR'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'monthly_cmip_hydro_rcp8.{key}_{gcm}.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobs_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obs_data' is not defined"
     ]
    }
   ],
   "source": [
    "if write_cache:\n",
    "    for key, ds in hist_data.items():\n",
    "        for gcm in models:\n",
    "            ds.sel(gcm=gcm).load().to_netcdf(os.path.join(os.environ['TMPDIR'], f'monthly_cmip_hydro_hist.{key}_{gcm}.nc'))\n",
    "    for key, ds in rcp4_data.items():\n",
    "        for gcm in models:\n",
    "            ds.sel(gcm=gcm).load().to_netcdf(os.path.join(os.environ['TMPDIR'], f'monthly_cmip_hydro_rcp4.{key}_{gcm}.nc'))\n",
    "    for key, ds in rcp8_data.items():\n",
    "        for gcm in models:\n",
    "            ds.sel(gcm=gcm).load().to_netcdf(os.path.join(os.environ['TMPDIR'], f'monthly_cmip_hydro_rcp8.{key}_{gcm}.nc'))\n",
    "#     for key, ds in obs_data.items():\n",
    "#             ds.sel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to see if reads in\n",
    "\n",
    "read_cache = True\n",
    "hist_data = {}\n",
    "rcp4_data = {}\n",
    "rcp8_data = {}\n",
    "if read_cache:\n",
    "    for key in ['loca', 'bcsd']:\n",
    "        hist_data[key] = xr.open_mfdataset(\n",
    "            os.path.join(cache_dir, f'monthly_cmip_hydro_hist.{key}_*.nc'),\n",
    "            concat_dim='gcm', chunks={'time': 72})\n",
    "        rcp4_data[key] = xr.open_mfdataset(\n",
    "            os.path.join(cache_dir, f'monthly_cmip_hydro_rcp4.{key}_*.nc'),\n",
    "            concat_dim='gcm', chunks={'time': 72})\n",
    "        rcp8_data[key] = xr.open_mfdataset(\n",
    "            os.path.join(cache_dir, f'monthly_cmip_hydro_rcp8.{key}_*.nc'),\n",
    "            concat_dim='gcm', chunks={'time': 72})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loca': <xarray.Dataset>\n",
       " Dimensions:       (gcm: 25, lat: 224, lon: 464, time: 1140)\n",
       " Coordinates:\n",
       "   * lat           (lat) float64 25.06 25.19 25.31 25.44 ... 52.69 52.81 52.94\n",
       "   * lon           (lon) float64 -124.9 -124.8 -124.7 ... -67.31 -67.19 -67.06\n",
       "   * time          (time) datetime64[ns] 2006-01-01 2006-02-01 ... 2100-12-01\n",
       "   * gcm           (gcm) <U14 'ACCESS1-0' 'CCSM4' ... 'bcc-csm1-1' 'inmcm4'\n",
       " Data variables:\n",
       "     ET            (gcm, time, lat, lon) float32 dask.array<shape=(25, 1140, 224, 464), chunksize=(1, 72, 224, 464)>\n",
       "     total_runoff  (gcm, time, lat, lon) float32 dask.array<shape=(25, 1140, 224, 464), chunksize=(1, 72, 224, 464)>\n",
       "     SWE           (gcm, time, lat, lon) float32 dask.array<shape=(25, 1140, 224, 464), chunksize=(1, 72, 224, 464)>,\n",
       " 'bcsd': <xarray.Dataset>\n",
       " Dimensions:       (gcm: 25, lat: 222, lon: 462, time: 1128)\n",
       " Coordinates:\n",
       "   * lon           (lon) float32 -124.6875 -124.5625 ... -67.1875 -67.0625\n",
       "   * lat           (lat) float32 25.1875 25.3125 25.4375 ... 52.6875 52.8125\n",
       "   * time          (time) datetime64[ns] 2006-01-01 2006-02-01 ... 2099-12-01\n",
       "   * gcm           (gcm) <U14 'ACCESS1-0' 'CCSM4' ... 'bcc-csm1-1' 'inmcm4'\n",
       " Data variables:\n",
       "     ET            (gcm, time, lat, lon) float32 dask.array<shape=(25, 1128, 222, 462), chunksize=(1, 72, 222, 462)>\n",
       "     total_runoff  (gcm, time, lat, lon) float32 dask.array<shape=(25, 1128, 222, 462), chunksize=(1, 72, 222, 462)>\n",
       "     SWE           (gcm, time, lat, lon) float32 dask.array<shape=(25, 1128, 222, 462), chunksize=(1, 72, 222, 462)>\n",
       " Attributes:\n",
       "     Conventions:        GDT 1.2\n",
       "     file_name:          conus_c5.access1-0_rcp85_r1i1p1.monthly.baseflow.2096.nc\n",
       "     History:            Archived Jan 2014\n",
       "     authors:            Wood, A. and Mizukami, N., with codes from T. Pruitt,...\n",
       "     description:        Monthly Average VIC Model Output for 1/8th Degree CON...\n",
       "     creation_date:      2014\n",
       "     institution:        NCAR, USACE, USBR\n",
       "     SurfSgnConvention:  Traditional}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcp8_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-loca]",
   "language": "python",
   "name": "conda-env-miniconda-loca-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
